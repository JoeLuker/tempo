# TEMPO Environment Variables
# Copy this file to .env and adjust values as needed

# Model Configuration
TEMPO_MODEL_ID=deepcogito/cogito-v1-preview-llama-3B
TEMPO_MODEL_DEVICE=auto  # auto, cuda, mps, cpu
TEMPO_MODEL_TORCH_DTYPE=auto  # auto, float16, bfloat16, float32
TEMPO_MODEL_QUANTIZATION=  # Leave empty for none, or use 4bit, 8bit
TEMPO_MODEL_TRUST_REMOTE_CODE=true

# Generation Defaults
TEMPO_GENERATION_MAX_LENGTH=200
TEMPO_GENERATION_TEMPERATURE=0.8
TEMPO_GENERATION_TOP_P=0.95
TEMPO_GENERATION_TOP_K=50
TEMPO_GENERATION_SELECTION_THRESHOLD=0.1

# Pruning Configuration
TEMPO_GENERATION_USE_RETROACTIVE_PRUNING=false
TEMPO_GENERATION_ATTENTION_THRESHOLD=0.01
TEMPO_GENERATION_USE_DYNAMIC_THRESHOLD=false

# API Configuration
TEMPO_API_HOST=0.0.0.0
TEMPO_API_PORT=8000
TEMPO_API_ENABLE_DOCS=true
TEMPO_API_CORS_ORIGINS=["http://localhost:5173", "http://localhost:5174"]

# Logging Configuration
TEMPO_LOGGING_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR
TEMPO_LOGGING_ENABLE_FILE_LOGGING=true
TEMPO_LOGGING_LOG_DIR=logs
TEMPO_LOGGING_CONSOLE_LOGGING=true

# Debug Configuration
TEMPO_DEBUG=false
TEMPO_DEBUG_MODULE_TOKEN_GENERATOR=false
TEMPO_DEBUG_MODULE_PARALLEL_GENERATOR=false
TEMPO_DEBUG_MODULE_ROPE_MODIFIER=false
TEMPO_DEBUG_MODULE_PRUNER=false

# Performance Configuration
TEMPO_DISABLE_KV_CACHE=false
TEMPO_LOW_CPU_MEM_USAGE=true

# HuggingFace Configuration (Optional)
# HF_TOKEN=your_huggingface_token_here
# HF_HOME=~/.cache/huggingface

# CUDA Configuration (Optional)
# CUDA_VISIBLE_DEVICES=0,1  # Specify GPU devices
# PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# System Configuration (Optional)
# OMP_NUM_THREADS=4  # Number of OpenMP threads
# MKL_NUM_THREADS=4  # Number of MKL threads